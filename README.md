# Neural Guide Android App

This Android app is designed to help blind users tell what is in front of their phone. It captures an image of what is in
front of them and reads out what it sees using a pretrained TensorFlow neural network accessed via a backend API.

The official backend API is held at https://www.neural-guide.me

This app was written as part of the Cambridge University Computer Science IB group project, for our client
[IMC](https://www.imc.com/eu/).

### Requirements

The Backend API is a Flask app held at https://github.com/Team-Lima/web-server. There is a Dockerfile to get set up easily held
in this repository to get set up quickly.
